{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef5724c0",
   "metadata": {},
   "source": [
    "# Recommender systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed44ddd0",
   "metadata": {},
   "source": [
    "## 1.1 Naive Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e662d097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6040</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "      <td>956716541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6040</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "      <td>956704887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6040</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "      <td>956704746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6040</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "      <td>956715648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6040</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "      <td>956715569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID  MovieID  Rating  Timestamp\n",
       "0             1     1193       5  978300760\n",
       "1             1      661       3  978302109\n",
       "2             1      914       3  978301968\n",
       "3             1     3408       4  978300275\n",
       "4             1     2355       5  978824291\n",
       "...         ...      ...     ...        ...\n",
       "1000204    6040     1091       1  956716541\n",
       "1000205    6040     1094       5  956704887\n",
       "1000206    6040      562       5  956704746\n",
       "1000207    6040     1096       4  956715648\n",
       "1000208    6040     1097       4  956715569\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import multiprocessing\n",
    "\n",
    "path = \"./ml-1m/ratings.dat\" # Read the dataset\n",
    "table = pd.read_table(path, sep=\"::\", names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"], \n",
    "                      engine=\"python\")\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5756af50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_col_mean(row_col, index,dataset): # Average of the row and col in the dataset\n",
    "    if row_col == \"row\":\n",
    "        return(dataset.loc[(dataset[\"UserID\"]==index), \"Rating\"].mean())\n",
    "    else:\n",
    "        return(dataset.loc[(dataset[\"MovieID\"]==index), \"Rating\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c74caf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataRouter(dataset): \n",
    "    \"\"\"\n",
    "    data preprocess for linear regression\n",
    "    dataset: train or test, pd dataframe\n",
    "    return: X, Y for linear regression\n",
    "    \"\"\"\n",
    "    user_mean = dict()\n",
    "    movie_mean = dict()\n",
    "    for i in dataset['UserID'].unique():\n",
    "        user_mean[i] = row_col_mean(\"row\", i, dataset)\n",
    "    for i in dataset['MovieID'].unique():\n",
    "        movie_mean[i] = row_col_mean(\"col\", i, dataset)\n",
    "    \n",
    "    dataset['X1'] = '' \n",
    "    dataset['X2'] = ''\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        dataset.loc[index, 'X1'] = user_mean[row['UserID']]\n",
    "        dataset.loc[index, 'X2'] = movie_mean[row['MovieID']]\n",
    "    X = dataset.loc[:,['X1','X2']].values\n",
    "    Y = dataset.loc[:,['Rating']].values  \n",
    "    return(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38b03ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearReg(X, Y):\n",
    "    reg = LinearRegression().fit(X, Y)\n",
    "    coef = reg.coef_\n",
    "    intercept = reg.intercept_\n",
    "    return(coef, intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3e827d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearRegNoIntercept(X, Y):\n",
    "    reg = LinearRegression(fit_intercept=False).fit(X, Y)\n",
    "    coef = reg.coef_\n",
    "    intercept = reg.intercept_\n",
    "    return(coef, intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64d5ebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(X, Y, coef, intercept): \n",
    "    \"\"\"\n",
    "    evaluation for linear regression\n",
    "    \"\"\"\n",
    "    reg = LinearRegression().fit(X, Y)\n",
    "    reg.coef_ = coef\n",
    "    reg.intercept_ = intercept\n",
    "    \n",
    "    y_pred = np.array(reg.predict(X))\n",
    "    y_pred = np.where(y_pred < 1, 1, y_pred)\n",
    "    y_pred = np.where(y_pred > 5, 5, y_pred)\n",
    "\n",
    "    rmse = np.sqrt(np.mean((Y - y_pred) ** 2))\n",
    "    mae = np.mean(np.abs(Y - y_pred))\n",
    "    return(rmse,mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aafec76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(mean_rmse, std_rmse, mean_mae, std_mae, info=\"Train\"):\n",
    "    \"\"\"\n",
    "    print the result\n",
    "    \"\"\"\n",
    "    print(f\"{info} RMSE Mean: {mean_rmse}\")\n",
    "    print(f\"{info} RMSE std: {std_rmse}\")\n",
    "    print(f\"\\n{info} MAE Mean: {mean_mae}\")\n",
    "    print(f\"{info} MAE std: {std_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e84a9ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kfold, test and train are set\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8402f499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE Mean: 0.9145443262957137\n",
      "Train RMSE std: 0.00042429662756855474\n",
      "\n",
      "Train MAE Mean: 0.7247995102650913\n",
      "Train MAE std: 0.00045659741953063055\n",
      "Test RMSE Mean: 0.9001653681660222\n",
      "Test RMSE std: 0.0016310273475170262\n",
      "\n",
      "Test MAE Mean: 0.7122092602307395\n",
      "Test MAE std: 0.001920795140638446\n",
      "CPU times: user 14min, sys: 4.76 s, total: 14min 5s\n",
      "Wall time: 13min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Liniear regression of two averages with intercept\n",
    "test_rmse_list = []\n",
    "test_mae_list = []\n",
    "train_rmse_list = []\n",
    "train_mae_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(table):\n",
    "    train = table.loc[train_index.tolist(), [\"UserID\", \"MovieID\", \"Rating\"]]\n",
    "    test = table.loc[test_index.tolist(), [\"UserID\", \"MovieID\", \"Rating\"]]\n",
    "    \n",
    "    X_train, Y_train = DataRouter(train)\n",
    "    X_test, Y_test = DataRouter(test)\n",
    "    coef, interc = LinearReg(X_train, Y_train)\n",
    "    test_rmse, test_mae = evaluation(X_test, Y_test, coef, interc)\n",
    "    train_rmse, train_mae = evaluation(X_train, Y_train, coef, interc)\n",
    "    test_rmse_list.append(test_rmse)\n",
    "    test_mae_list.append(test_mae)\n",
    "    train_rmse_list.append(train_rmse)\n",
    "    train_mae_list.append(train_mae)\n",
    "\n",
    "report(np.mean(train_rmse_list), np.std(train_rmse_list), np.mean(train_mae_list), \n",
    "       np.std(train_mae_list), info=\"Train\")\n",
    "report(np.mean(test_rmse_list), np.std(test_rmse_list), np.mean(test_mae_list), \n",
    "       np.std(test_mae_list), info=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a583662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE Mean: 0.9465499537839577\n",
      "Train RMSE std: 0.0003342578808442147\n",
      "\n",
      "Train MAE Mean: 0.7585512269178818\n",
      "Train MAE std: 0.0003182251782626315\n",
      "Test RMSE Mean: 0.9344570734200918\n",
      "Test RMSE std: 0.00127624501554858\n",
      "\n",
      "Test MAE Mean: 0.748706056925681\n",
      "Test MAE std: 0.0012824171256624554\n",
      "CPU times: user 13min 51s, sys: 4.05 s, total: 13min 55s\n",
      "Wall time: 13min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Liniear regression of two averages without intercept\n",
    "test_rmse_list = []\n",
    "test_mae_list = []\n",
    "train_rmse_list = []\n",
    "train_mae_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(table):\n",
    "    train = table.loc[train_index.tolist(), [\"UserID\", \"MovieID\", \"Rating\"]]\n",
    "    test = table.loc[test_index.tolist(), [\"UserID\", \"MovieID\", \"Rating\"]]\n",
    "    \n",
    "    X_train, Y_train = DataRouter(train)\n",
    "    X_test, Y_test = DataRouter(test)\n",
    "    coef, interc = LinearRegNoIntercept(X_train, Y_train)\n",
    "    test_rmse, test_mae = evaluation(X_test, Y_test, coef, interc)\n",
    "    train_rmse, train_mae = evaluation(X_train, Y_train, coef, interc)\n",
    "    test_rmse_list.append(test_rmse)\n",
    "    test_mae_list.append(test_mae)\n",
    "    train_rmse_list.append(train_rmse)\n",
    "    train_mae_list.append(train_mae)\n",
    "    \n",
    "report(np.mean(train_rmse_list), np.std(train_rmse_list), np.mean(train_mae_list), \n",
    "       np.std(train_mae_list), info=\"Train\")\n",
    "report(np.mean(test_rmse_list), np.std(test_rmse_list), np.mean(test_mae_list), \n",
    "       np.std(test_mae_list), info=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27376e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_avg(dataset): # Calculate Global average rating\n",
    "    ga = dataset['Rating'].mean()\n",
    "    return(ga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "551d822c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE Mean: 1.1171011110023854\n",
      "Train RMSE std: 0.0004203500090281157\n",
      "\n",
      "Train MAE Mean: 0.9338607806758029\n",
      "Train MAE std: 0.00038334720904158897\n",
      "Test RMSE Mean: 1.1170984720424795\n",
      "Test RMSE std: 0.0016813423548895845\n",
      "\n",
      "Test MAE Mean: 0.9338595477225654\n",
      "Test MAE std: 0.001534945750123129\n",
      "CPU times: user 792 ms, sys: 143 ms, total: 934 ms\n",
      "Wall time: 933 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_rmse_list = []\n",
    "test_mae_list = []\n",
    "train_rmse_list = []\n",
    "train_mae_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(table):\n",
    "    train = table.loc[train_index.tolist(), [\"UserID\", \"MovieID\", \"Rating\"]]\n",
    "    test = table.loc[test_index.tolist(), [\"UserID\", \"MovieID\", \"Rating\"]]\n",
    "    \n",
    "    test_rmse = np.sqrt(np.mean((test['Rating'] - global_avg(test))**2))\n",
    "    test_mae = np.mean(np.abs(test['Rating']- global_avg(test)))\n",
    "    train_rmse = np.sqrt(np.mean((train['Rating'] - global_avg(train))**2))\n",
    "    train_mae = np.mean(np.abs(train['Rating'] - global_avg(train)))\n",
    "\n",
    "    test_rmse_list.append(test_rmse)\n",
    "    test_mae_list.append(test_mae)\n",
    "    train_rmse_list.append(train_rmse)\n",
    "    train_mae_list.append(train_mae)\n",
    "    \n",
    "report(np.mean(train_rmse_list), np.std(train_rmse_list), np.mean(train_mae_list), \n",
    "       np.std(train_mae_list), info=\"Train\")\n",
    "report(np.mean(test_rmse_list), np.std(test_rmse_list), np.mean(test_mae_list), \n",
    "       np.std(test_mae_list), info=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a93ca295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE Mean: 1.0276718866687955\n",
      "Train RMSE std: 0.0005528163518390866\n",
      "\n",
      "Train MAE Mean: 0.8227317798294085\n",
      "Train MAE std: 0.0004731890438345407\n",
      "Test RMSE Mean: 1.0354887413559504\n",
      "Test RMSE std: 0.002196430566260904\n",
      "\n",
      "Test MAE Mean: 0.8290076950378905\n",
      "Test MAE std: 0.0017401821127500715\n",
      "CPU times: user 1.11 s, sys: 267 ms, total: 1.38 s\n",
      "Wall time: 1.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Average rating per user\n",
    "test_rmse_list = []\n",
    "test_mae_list = []\n",
    "train_rmse_list = []\n",
    "train_mae_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(table):\n",
    "    train = table.loc[train_index.tolist(), [\"UserID\", \"MovieID\", \"Rating\"]]\n",
    "    test = table.loc[test_index.tolist(), [\"UserID\", \"MovieID\", \"Rating\"]]\n",
    "    \n",
    "    user_avg = train[['UserID','Rating']].groupby('UserID').mean().rename(columns={'Rating':'Average'})\n",
    "    train_merge = pd.merge(train, user_avg, on='UserID')\n",
    "    test_merge = pd.merge(test, user_avg, on='UserID')\n",
    "\n",
    "    test_rmse = np.sqrt(np.mean((test_merge['Rating'] - test_merge['Average'])**2))\n",
    "    test_mae = np.mean(np.abs(test_merge['Rating']- test_merge['Average']))\n",
    "    train_rmse = np.sqrt(np.mean((train_merge['Rating'] - train_merge['Average'])**2))\n",
    "    train_mae = np.mean(np.abs(train_merge['Rating'] - train_merge['Average']))\n",
    "\n",
    "    test_rmse_list.append(test_rmse)\n",
    "    test_mae_list.append(test_mae)\n",
    "    train_rmse_list.append(train_rmse)\n",
    "    train_mae_list.append(train_mae)\n",
    "    \n",
    "report(np.mean(train_rmse_list), np.std(train_rmse_list), np.mean(train_mae_list), \n",
    "       np.std(train_mae_list), info=\"Train\")\n",
    "report(np.mean(test_rmse_list), np.std(test_rmse_list), np.mean(test_mae_list), \n",
    "       np.std(test_mae_list), info=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8730c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE Mean: 0.9742112263767705\n",
      "Train RMSE std: 0.00018290851118296756\n",
      "\n",
      "Train MAE Mean: 0.7783430056529332\n",
      "Train MAE std: 0.00028529865704437574\n",
      "Test RMSE Mean: 0.9794200889294983\n",
      "Test RMSE std: 0.0007691010494227671\n",
      "\n",
      "Test MAE Mean: 0.782308674322367\n",
      "Test MAE std: 0.0006285312602745488\n",
      "CPU times: user 1.18 s, sys: 247 ms, total: 1.43 s\n",
      "Wall time: 1.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Average rating per item\n",
    "test_rmse_list = []\n",
    "test_mae_list = []\n",
    "train_rmse_list = []\n",
    "train_mae_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(table):\n",
    "    train = table.loc[train_index.tolist(), [\"UserID\", \"MovieID\", \"Rating\"]]\n",
    "    test = table.loc[test_index.tolist(), [\"UserID\", \"MovieID\", \"Rating\"]]\n",
    "    \n",
    "    movie_avg = train[['MovieID','Rating']].groupby('MovieID').mean().rename(columns={'Rating':'Average'})\n",
    "    train_merge = pd.merge(train, movie_avg, on='MovieID')\n",
    "    test_merge = pd.merge(test, movie_avg, on='MovieID')\n",
    "\n",
    "    test_rmse = np.sqrt(np.mean((test_merge['Rating'] - test_merge['Average'])**2))\n",
    "    test_mae = np.mean(np.abs(test_merge['Rating']- test_merge['Average']))\n",
    "    train_rmse = np.sqrt(np.mean((train_merge['Rating'] - train_merge['Average'])**2))\n",
    "    train_mae = np.mean(np.abs(train_merge['Rating'] - train_merge['Average']))\n",
    "\n",
    "    test_rmse_list.append(test_rmse)\n",
    "    test_mae_list.append(test_mae)\n",
    "    train_rmse_list.append(train_rmse)\n",
    "    train_mae_list.append(train_mae)\n",
    "    \n",
    "report(np.mean(train_rmse_list), np.std(train_rmse_list), np.mean(train_mae_list), \n",
    "       np.std(train_mae_list), info=\"Train\")\n",
    "report(np.mean(test_rmse_list), np.std(test_rmse_list), np.mean(test_mae_list), \n",
    "       np.std(test_mae_list), info=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003ef338",
   "metadata": {},
   "source": [
    "### A Parent Class for Task 1.2 and 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9407042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import random\n",
    "\n",
    "path = \"./ml-1m/ratings.dat\"\n",
    "seeds = 1\n",
    "\n",
    "class MatrixModels():\n",
    "    \"\"\"\n",
    "    The template for task 1.2 and 1.3.\n",
    "    Args:\n",
    "        path: File path.\n",
    "        num_factors: The number of features.\n",
    "        num_iter: Max iterations.\n",
    "        seeds: Set the random state.\n",
    "        save_UM: Save the feature matrices.\n",
    "        save_info: Path to save feature matrices.\n",
    "        random_normal: The matrix initialization method.\n",
    "    \"\"\"\n",
    "    def __init__(self, path, num_factors, num_iter, seeds, save_UM, save_info=\"\", random_normal=True):\n",
    "        self.path = path\n",
    "        self.num_factors = num_factors\n",
    "        self.num_iter = num_iter\n",
    "        self.seeds = seeds\n",
    "        self.save_UM = save_UM\n",
    "        self.save_info = save_info\n",
    "        self.random_normal = random_normal\n",
    "        self.I = 6040\n",
    "        self.J = 3952\n",
    "        self.table = pd.read_table(self.path, sep=\"::\", names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"], \n",
    "                                   engine=\"python\")\n",
    "    \n",
    "    def _evaluation(self, U, M, table):\n",
    "        \"\"\"\n",
    "        Evaluate model performance.\n",
    "        \"\"\"\n",
    "        y_true = table[:, 2]\n",
    "        y_pred = []\n",
    "        \n",
    "        for i in range(table.shape[0]):\n",
    "            y_pred.append(np.matmul(U[table[i, 0] - 1, :], M[:, table[i, 1] - 1]))\n",
    "        \n",
    "        # If y_pred < 1, y_pred = 1. If y_pred > 5, y_pred = 5.\n",
    "        y_pred = np.array(y_pred)\n",
    "        y_pred = np.where(y_pred < 1, 1, y_pred)\n",
    "        y_pred = np.where(y_pred > 5, 5, y_pred)\n",
    "        \n",
    "        # Calculate RMSE and MAE\n",
    "        rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "        mae = np.mean(np.abs(y_true - y_pred))\n",
    "        return rmse, mae\n",
    "    \n",
    "    def _train_iteration(U, M, table_train):\n",
    "        print(\"Implement this method.\")\n",
    "        return U, M\n",
    "        \n",
    "    def run_model(self, train_index, test_index, num_work=0):\n",
    "        \"\"\"\n",
    "        Run the experiment on one fold.\n",
    "        \"\"\"\n",
    "        table_train, table_test = self.table.iloc[train_index], self.table.iloc[test_index]\n",
    "        table_train, table_test = table_train.to_numpy(), table_test.to_numpy()\n",
    "\n",
    "        # Initialization\n",
    "        if self.random_normal:\n",
    "            np.random.seed(self.seeds)\n",
    "            U = np.random.normal(0, 0.1, (self.I, self.num_factors))\n",
    "            np.random.seed(self.seeds)\n",
    "            M = np.random.normal(0, 0.1, (self.num_factors, self.J))\n",
    "        else:\n",
    "            U = np.ones((self.I, self.num_factors))\n",
    "            M = np.ones((self.num_factors, self.J))\n",
    "\n",
    "        # Training model\n",
    "        for epoch in range(num_iter):\n",
    "            info = f\"\\rWorker {num_work}: {epoch} epoch.\\r\"\n",
    "            print(info, end=\"\")\n",
    "            U, M = self._train_iteration(U, M, table_train)\n",
    "            print(\" \" * len(info), end=\"\")\n",
    "            \n",
    "        # Save results\n",
    "        if self.save_UM:\n",
    "            np.save(f\"./UM/{self.save_info}_U_{num_work}.npy\", U) \n",
    "            np.save(f\"./UM/{self.save_info}_M_{num_work}.npy\", M)\n",
    "        \n",
    "        # Evaluating model\n",
    "        train_rmse, train_mae = self._evaluation(U, M, table_train)\n",
    "        self.train_rmse_lst.append(train_rmse)\n",
    "        self.train_mae_lst.append(train_mae)\n",
    "        \n",
    "        test_rmse, test_mae = self._evaluation(U, M, table_test)\n",
    "        self.test_rmse_lst.append(test_rmse)\n",
    "        self.test_mae_lst.append(test_mae)\n",
    "        \n",
    "        print(f\"\\rWorker {num_work}: Done.\\nTrain RMSE: {train_rmse}, MAE: {train_mae}.\\nTest RMSE: {test_rmse}, MAE: {test_mae}.\")\n",
    "        \n",
    "    def main(self):\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=self.seeds) # five folds\n",
    "        arg_lst = []\n",
    "        num_work = 1\n",
    "        for train_index, test_index in kf.split(self.table):\n",
    "            arg_lst.append((train_index, test_index, num_work))\n",
    "            num_work += 1\n",
    "        \n",
    "        # Multiprocessing\n",
    "        manager = multiprocessing.Manager()\n",
    "        self.train_rmse_lst = manager.list()\n",
    "        self.train_mae_lst = manager.list()\n",
    "        self.test_rmse_lst = manager.list()\n",
    "        self.test_mae_lst = manager.list()\n",
    "        workers = []\n",
    "        for i in range(5):\n",
    "            p = multiprocessing.Process(target=self.run_model, args=arg_lst[i])\n",
    "            workers.append(p)\n",
    "            p.start()\n",
    "\n",
    "        for p in workers:\n",
    "            p.join()\n",
    "\n",
    "        self.train_rmse_lst = np.array(self.train_rmse_lst)\n",
    "        self.train_mae_lst = np.array(self.train_mae_lst)\n",
    "        self.test_rmse_lst = np.array(self.test_rmse_lst)\n",
    "        self.test_mae_lst = np.array(self.test_mae_lst)\n",
    "        \n",
    "        print(f\"\\nTrain RMSE Mean: {np.mean(self.train_rmse_lst)}\")\n",
    "        print(f\"Train RMSE std: {np.std(self.train_rmse_lst)}\")\n",
    "        print(f\"\\nTrain MAE Mean: {np.mean(self.train_mae_lst)}\")\n",
    "        print(f\"Train MAE std: {np.std(self.train_mae_lst)}\")\n",
    "        \n",
    "        print(f\"\\nTest RMSE Mean: {np.mean(self.test_rmse_lst)}\")\n",
    "        print(f\"Test RMSE std: {np.std(self.test_rmse_lst)}\")\n",
    "        print(f\"\\nTest MAE Mean: {np.mean(self.test_mae_lst)}\")\n",
    "        print(f\"Test MAE std: {np.std(self.test_mae_lst)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929c46d1",
   "metadata": {},
   "source": [
    "## 1.2 UV Matrix Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d67dcb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UVDecomposition(MatrixModels):\n",
    "    \"\"\"\n",
    "    Implement 1.2 UV Matrix Decomposition.\n",
    "    Args:\n",
    "        path: File path.\n",
    "        num_factors: The number of features.\n",
    "        num_iter: Max iterations.\n",
    "        seeds: Set the random state.\n",
    "        save_UM: Save the feature matrices.\n",
    "        save_info: Path to save feature matrices. \n",
    "        random_normal: The matrix initialization method.\n",
    "    \"\"\"\n",
    "    def __init__(self, path, num_factors, num_iter, seeds, save_UM, save_info=\"\", random_normal=False):\n",
    "        super().__init__(path, num_factors, num_iter, seeds, save_UM, save_info, random_normal)\n",
    "        \n",
    "    def _update_U(self, index, table_train, U, V):\n",
    "        r, s = index\n",
    "        sum_1 = 0\n",
    "        sum_2 = 0\n",
    "        M = table_train[table_train[:, 0] == (r + 1), :]\n",
    "        \n",
    "        for row in range(M.shape[0]):\n",
    "            j = M[row, 1] - 1\n",
    "            prod = np.matmul(U[r, :], V[:, j]) - U[r, s] * V[s, j]\n",
    "            sum_1 += V[s, j] * (M[row, 2] - prod)\n",
    "            sum_2 += V[s, j] ** 2\n",
    "            \n",
    "        if sum_2 == 0:\n",
    "            sum_2 = 0.001\n",
    "        U[r, s] = sum_1 / sum_2\n",
    "        return U\n",
    "\n",
    "    def _update_V(self, index, table_train, U, V):\n",
    "        r, s = index\n",
    "        sum_1 = 0\n",
    "        sum_2 = 0\n",
    "        M = table_train[table_train[:, 1] == (s + 1), :]\n",
    "\n",
    "        for row in range(M.shape[0]):\n",
    "            i = M[row, 0] - 1\n",
    "            prod = np.matmul(U[i, :], V[:, s]) - U[i, r] * V[r, s]\n",
    "            sum_1 += U[i, r] * (M[row, 2] - prod)\n",
    "            sum_2 += U[i, r] ** 2\n",
    "        \n",
    "        if sum_2 == 0:\n",
    "            sum_2 = 0.001\n",
    "        V[r, s] = sum_1 / sum_2\n",
    "        return V\n",
    "        \n",
    "    def _train_iteration(self, U, V, table_train):\n",
    "        \"\"\"\n",
    "        One iteration of training model.\n",
    "        \"\"\"\n",
    "        u_index = list(np.ndindex(U.shape))\n",
    "        v_index = list(np.ndindex(V.shape))\n",
    "        random.shuffle(u_index)\n",
    "        random.shuffle(v_index)\n",
    "        while (len(u_index) > 0) | (len(v_index) > 0):\n",
    "            if (len(u_index) > 0):\n",
    "                u = u_index.pop()\n",
    "                U = self._update_U(u, table_train, U, V)\n",
    "            if (len(v_index) > 0):\n",
    "                v = v_index.pop()\n",
    "                V = self._update_V(v, table_train, U, V)\n",
    "        return U, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd6f26e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:4\u001b[0m\n",
      "Cell \u001b[0;32mIn [26], line 14\u001b[0m, in \u001b[0;36mUVDecomposition.__init__\u001b[0;34m(self, path, num_factors, num_iter, seeds, save_UM, save_info, random_normal)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, path, num_factors, num_iter, seeds, save_UM, save_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, random_normal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_factors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_UM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_normal\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [25], line 35\u001b[0m, in \u001b[0;36mMatrixModels.__init__\u001b[0;34m(self, path, num_factors, num_iter, seeds, save_UM, save_info, random_normal)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mI \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6040\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mJ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3952\u001b[39m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m::\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUserID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMovieID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRating\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTimestamp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpython\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/sna/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/sna/lib/python3.10/site-packages/pandas/io/parsers/readers.py:779\u001b[0m, in \u001b[0;36mread_table\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    764\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    765\u001b[0m     dialect,\n\u001b[1;32m    766\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    775\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    776\u001b[0m )\n\u001b[1;32m    777\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 779\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/sna/lib/python3.10/site-packages/pandas/io/parsers/readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    580\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 581\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/sna/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1254\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1252\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1253\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1254\u001b[0m     index, columns, col_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[1;32m   1255\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1256\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/sna/lib/python3.10/site-packages/pandas/io/parsers/python_parser.py:238\u001b[0m, in \u001b[0;36mPythonParser.read\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, rows: \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    237\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m         content \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_lines(rows)\n\u001b[1;32m    239\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_chunk:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/sna/lib/python3.10/site-packages/pandas/io/parsers/python_parser.py:1091\u001b[0m, in \u001b[0;36mPythonParser._get_lines\u001b[0;34m(self, rows)\u001b[0m\n\u001b[1;32m   1088\u001b[0m rows \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   1090\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1091\u001b[0m     new_row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_iter_line(row_num\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpos \u001b[39m+\u001b[39;49m rows \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m   1092\u001b[0m     rows \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1094\u001b[0m     \u001b[39mif\u001b[39;00m new_row \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/sna/lib/python3.10/site-packages/pandas/io/parsers/python_parser.py:759\u001b[0m, in \u001b[0;36mPythonParser._next_iter_line\u001b[0;34m(self, row_num)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[39mWrapper around iterating through `self.data` (CSV source).\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[39m    The row number of the line being parsed.\u001b[39;00m\n\u001b[1;32m    756\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    757\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    758\u001b[0m     \u001b[39m# assert for mypy, data is Iterator[str] or None, would error in next\u001b[39;00m\n\u001b[0;32m--> 759\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    760\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n\u001b[1;32m    761\u001b[0m     \u001b[39m# for mypy\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_factors = 5\n",
    "num_iter = 30\n",
    "\n",
    "model = UVDecomposition(path, num_factors, num_iter, seeds, False)\n",
    "model.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39550153",
   "metadata": {},
   "source": [
    "## 1.3 Matrix Factorization\n",
    "- Update the weights based on the rows or columns of matrices,\n",
    "$$\n",
    "\\begin{align*}\n",
    "    U^{(t+1)}[i, :] &= U^{(t)}[i, :] + \\eta\\left( 2e_{ij}M^{(t)}[:, j] - \\lambda U^{(t)}[i, :] \\right) \\\\\n",
    "    M^{(t+1)}[:, j] &= M^{(t)}[:, j] + \\eta\\left( 2e_{ij}U^{(t)}[i, :] - \\lambda M^{(t)}[:, j] \\right) \n",
    "\\end{align*}\n",
    "$$\n",
    "- Set the random seed to 1 both in weights initialization and five-fold division.\n",
    "- Multiprocessing programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b773288",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GravityTikk(MatrixModels):\n",
    "    \"\"\"\n",
    "    Implement 1.3 Matrix Factorization.\n",
    "    Args:\n",
    "        path: File path.\n",
    "        num_factors: The number of features.\n",
    "        num_iter: Max iterations.\n",
    "        seeds: Set the random state.\n",
    "        save_UM: Save the feature matrices.\n",
    "        save_info: Path to save feature matrices.\n",
    "        regularization: factor lambda of regularization term.\n",
    "        learn_rate: Learning rate.\n",
    "    \"\"\"\n",
    "    def __init__(self, path, num_factors, num_iter, seeds, save_UM, save_info, regularization, learn_rate):\n",
    "        super().__init__(path, num_factors, num_iter, seeds, save_UM, save_info)\n",
    "        self.regularization = regularization\n",
    "        self.learn_rate = learn_rate\n",
    "    \n",
    "    def _train_iteration(self, U, M, table_train):\n",
    "        \"\"\"\n",
    "        One iteration of training model.\n",
    "        \"\"\"\n",
    "        for i in range(table_train.shape[0]):\n",
    "            # Calculate the error\n",
    "            error = table_train[i, 2] - np.matmul(U[table_train[i, 0] - 1, :], M[:, table_train[i, 1] - 1])\n",
    "        \n",
    "            # Calculate the gradient\n",
    "            gradient_U = 2 * error * M[:, table_train[i, 1] - 1] - self.regularization * U[table_train[i, 0] - 1, :]\n",
    "            gradient_M = 2 * error * U[table_train[i, 0] - 1, :] - self.regularization * M[:, table_train[i, 1] - 1]\n",
    "            \n",
    "            # Update U, M\n",
    "            U[table_train[i, 0] - 1, :] += self.learn_rate * gradient_U\n",
    "            M[:, table_train[i, 1] - 1] += self.learn_rate * gradient_M\n",
    "        \n",
    "        return U, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61452721",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Hyperparameters: Setting 1, Suggested Setting\n",
    "num_factors = 10\n",
    "num_iter = 75\n",
    "regularization = 0.05\n",
    "learn_rate = 0.005\n",
    "\n",
    "model = GravityTikk(path, num_factors, num_iter, seeds, True, \"Setting_1\", regularization, learn_rate)\n",
    "model.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf0aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Hyperparameters: Setting 2\n",
    "num_factors = 20\n",
    "num_iter = 75\n",
    "regularization = 0.05\n",
    "learn_rate = 0.005\n",
    "\n",
    "model = GravityTikk(path, num_factors, num_iter, seeds, True, \"Setting_2\", regularization, learn_rate)\n",
    "model.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9757d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Hyperparameters: Setting 3\n",
    "num_factors = 10\n",
    "num_iter = 100\n",
    "regularization = 0.05\n",
    "learn_rate = 0.005\n",
    "\n",
    "model = GravityTikk(path, num_factors, num_iter, seeds, True, \"Setting_3\", regularization, learn_rate)\n",
    "model.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0e2085",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Hyperparameters: Setting 4\n",
    "num_factors = 10\n",
    "num_iter = 75\n",
    "regularization = 0.01\n",
    "learn_rate = 0.005\n",
    "\n",
    "model = GravityTikk(path, num_factors, num_iter, seeds, True, \"Setting_4\", regularization, learn_rate)\n",
    "model.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56baca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Hyperparameters: Setting 5\n",
    "num_factors = 10\n",
    "num_iter = 75\n",
    "regularization = 0.05\n",
    "learn_rate = 0.001\n",
    "\n",
    "model = GravityTikk(path, num_factors, num_iter, seeds, True, \"Setting_5\", regularization, learn_rate)\n",
    "model.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('sna')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e66268ec146ab187027fc60197ad46dfe791325fbb8008d3dd33801282ed846b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
